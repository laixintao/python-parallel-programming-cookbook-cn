内存管理
========

内存管理是并行架构需要考虑的另一方面，确切来说是获得数据的方式。无论处理单元多快，如果内存提供指令和数据的速度跟不上，就会造成系统的瓶颈。制约内存响应时间与处理器速度相匹配的主要因素是内存循环时间。所谓循环时间就是两次连续操作之间所消耗的时间。处理器的循环时间通常比内存循环时间短得多。当处理器传送数据到内存或从内存中获取数据时，内存依旧在内存循环中，其他任何设备（I/O控制器，处理器）都不能使用内存，以为内存必须先对上一个请求作出响应。

.. image:: ../images/Page-7-Image-1.png

不同的人为了解决 MIMD 架构获取内存数据的问题，分别提出了两种内存管理系统。第一种就是人们所熟知的共享内存系统，共享内存系统有大量的虚拟内存空间，而且处理器能够公平访问内存中的数据和指令。另外一种类型是分布式内存模型，在这种内存模型中，每个处理器都有自己专属的内存，其他处理器都不能访问。共享内存和分布式内存本质上的区别是虚拟内存的结构，以处理器的角度来说是内存的位置不一样。 一般来说，每个系统的内存都会分为能独立访问的不同部分，共享内存和分布式内存系统的处理单元管理内存访问的方式不同。 
``load R0,i`` 
指令意味着将内存中
``i``
位置的内容加载进
``R0``
寄存器，但在不同的内存管理下处理器的处理方式不尽相同。在共享内存的系统中，
``i``
代表的是内存的全局地址，对于系统中的所有处理器都指向同一块内存空间。如果两个处理器通向想要执行该内存中的指令，它们会向
``R0``
寄存器载入相同的信息。在分布式内存系统中，
``i``
是局部地址。如果两个处理器同时执行向
``R0``
载入内容的语句，执行结束之后，不同处理器
``R0``
寄存器中的值一般情况下是不一样的，因为每个处理器对应的内存块中的``i``代表的全局地址不一样。对于程序员来说，必须区分共享内存和分布式内存，因为在并行编程中需要考量内存管理方式来决定进程或线程间通信的方式。对于系统来说，共享内存能够在内存中构建数据结构并在子进程间直接交换该数据结构的引用。而对于分布式内存系统来说，必须在局部内存保存共享数据的副本。一个处理器会向其他处理器发送含有共享数据的消息从而创建数据副本。这就导致了这种内存管理的一个缺点，那就是，当要发送的消息太大，发送过程会耗费相对较长的时间。

共享内存
--------

下图展示了共享内存多处理器系统的架构，这里只展示了各部件之间的简单连接。总线结构允许任意数量的设备共享通道。总线协议最初设计是让单处理器，一个或多个磁盘和磁带控制器通过共享内存进行通信。各个处理器共用一个Cache，Cache中保存着局部内存中很有可能被处理器使用的指令或数据。可以想象以下，当一个处理器修改了内存中的数据，同时另外一个处理器正在使用这个数据时，就会出现问题。已修改的值会从处理器的Cache传递到共享内存中，接着，这个新值对所有处理器都是可见的，那么它们希望使用旧值完成运算是不可能的。这就是人们所熟知的Cache一致性问题，内存一致性问题的特殊情况，要解决这个问题需要硬件像多进程编程一样实现处理并发问题和同步控制。

.. image:: ../images/Page-8-Image-1.png

共享内存系统的主要特性如下：

- 内存对于所用处理器来说是一样的，例如，所有处理器所对应相同的数据结构都存在于相同的逻辑地址，也就是说可以从相同的内存地址中获得该数据结构。

- 通过同步控制可以控制处理器对共享内存的访问权限。实际上，只有一个处理器拥有对内存资源的访问权限。

- 共享内存很快，两个任务通信的时间和读取单个内存地址的时间相等（取决于内存的访问速度）

在共享内存系统中访问内存的方式如下

- 均匀内存访问 (Uniform memory access (UMA) )：这类系统的基本特征是无论是对于处理器还是对任意的内存区域，访问时间都是连续不断的。因此，这些系统也成为对称式多处理器 (symmetric multiprocessor (SMP)) 系统。这类系统实现起来相对简单，但是可扩展性较差，程序员需要通过添加适当的控制，信号量和锁等来管理资源，程序员也有责任来管理同步控制。

- 非均匀内存访问 (Non-uniform memory access (NUMA))：这类架构将内存分为高速访问区域和低速访问区域。高速访问区域是分配给各个浏览器的区域，是用于数据交换的公用区域。这类系统也称为分布式共享内存系统 (Distributed Shared Memory Systems (DSM)) ，这类系统的扩展性很好，但开发难度较高。

- 无远程内存访问 (No remote memory access (NORMA))：一般情况下，这类系统的内存在处理器之间是分布存在的。局部内存是私有的，只有对应的处理器才可以访问。处理器之间通过消息传递协议通信。

- 仅Cache可访问 (Cache only memory access (COMA))：这类系统中仅有Cache内存。分析 NUMA 架构时，可以注意到会把数据的副本保存在Cache中供处理器使用，而在主存中也保留着重复的数据。COMA 架构可以移除重复的主存数据，而只保留Cache内存。

分布式内存
---------

在使用分布式内存的系统中，各个处理器都有其各自的内存，而且每个处理器只能处理属于自己的内存。某些学者把这类系统称为“多计算机系统”，这个名字很真实地反映了组成这类系统的元素能够独立作为一个具有内存和处理器的微型系统，如下图所示：

.. image:: ../images/Page-10-Image-1.png

这种内存管理方式有几个好处。第一，总线和开关级别的的通信中不会有冲突。每个处理器都可以无视其他处理器的干扰而独自占有局部内存的带宽；第二，没有通用总线意味着没有处理器数量的限制，系统的规模只局限于连接处理器的网络带宽；第三，没有Cache一致性问题的困扰。每个处理器只需要处理属于自己的数据而无须上传数据副本的问题。但最大的缺点是，很难实现处理器之间的通信。如果一个处理器需要其他处理器的数据，这两个处理器必须要通过消息传递协议来交换消息。在这里介绍两个速度瓶颈的来源，首先，从一个处理器创建和发送消息到另外一个处理器需要时间；接着，任何处理器都需要停止工作，处理来自其他处理器的消息。面向分布式内存机器的程序必须一系列通过消息通信的独立任务。

.. image:: ../images/Page-11-Image-1.png

分布式内存系统的特性如下：

- 内存通常分布在不同的处理器之中，局部内存只能由对应的处理器访问。

- 同步控制通过在处理器之间移动数据 (即使是消息本身) 来实现 (通信)。

- 局部内存的数据分支会影响机器的性能——有必要精确地进行数据分割最小化 CPU 间的通信。另外，协调数据的分解合成操作的处理器必须与处理部分数据的处理器高效地通信。

- 消息传递协议用于 CPU 间通过交换数据包通信。消息是信息的分解单元，他们经过良好的定义，所以处理器之间能够准确地识别出消息地内容。

大量的并行处理 (Massively parallel processing (MPP))
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

MPP 机器由上百个处理器 (在一些机器中达到成千上万个) 通过通信网络连接而成。世界上最快的计算机就是基于这种架构，采用这种架构的系统有:Earth Simulator， Blue Gene， ASCI White， ASCI Red， ASCI Purple 以及 Red Storm 等。

工作站集群
>>>>>>>>>>

工作站集群是指将传统的计算机通过通信网络连接起来。在集群架构中，一个节点就是集群中的一个计算单元。对于用户来说，集群是完全透明的，掩盖了软硬件的复杂性，使得数据以及应用仿佛从一个节点中得到的。

在这里，会定义三种集群：

- 故障切换集群 (The fail-over cluster) ：在这类集群中，会持续检测节点的活动状态，当一个节点出现故障，另外一台机器会接管故障节点的工作。通过这种冗余架构可以保证系统的可用性。

- 负载均衡集群 (The load balancing cluster) ：在这类系统中，会将一个作业请求发送给负载较小的节点上执行。这样做可以减少整个处理过程所耗费的时间。

- 高性能计算集群 (The high-performance cluster) :在这类系统中，每个节点都可以提供极高的性能，一个任务依旧分解为若干个子任务交给各个节点处理。任务会分给不同的机器进行并行处理。

异构架构
>>>>>>>>

在同构的超级计算机中采用GPU加速器改变了之前超级计算机的使用规则。即使GPU能够提供高性能计算，但是不能把它看作一个独立的处理单元，因为GPU必须配合CPU才能顺利工作。因此，异构计算的编程范式很简单，首先CPU通过各种方式计算和控制任务，将计算密集型和具有高并行性的任务分配给图形加速卡执行。CPU和GPU之间的通信可以通过高速总线和某块共享内存 (物理内存或者虚拟内存)。事实上，在这类设备上GPU和CPU都没有独立的内存区域，一般是在由各种编程模型(如CUDA，OpenCL)提供的公用内存区域中使用库。这类架构被称之为异构架构，在这种架构中，应用程序可以在单一的地址空间中创建数据结构，然后将任务发送给能完成的硬件执行。通过原子操作，多个任务可以安全地操控同一个内存区域同时避免数据一致性问题。所以，尽管CPU和GPU看起来不能高效联合工作，但通过新的架构可以优化它们之间的交互和并行程序的性能。

.. image:: ../images/Page-13-Image-1.png