并行编程模型
============

并行编程模型是作为对硬件和内存架构的抽象而存在的。事实上，这些模式不是特定的而且不涉及某特定类型的机器及内存架构。他们在理论上能在任何类型的机器上实现。相对于前面的架构细分，这些编程模型会在更高的层面上构建，用于表示软件执行并行计算时必须实现的方式。为了访问内存和分解任务，每一个模型都有它独自的方式和其他处理器共享信息。

需要明白的是没有最好的编程模型，应用效果最好的模型和待解决问题的耦合度较高。使用范围最广的并行编程模型有：

- 共享内存模型

- 多线程模型

- 分布式内存/消息传递模型

- 数据并行模型

在这节中，会描述这些编程模型的概览。在下一章会更加准确的描述这些编程模型，并会介绍Python中实现这些模型的相应模块。

共享内存模型
------------

在这个编程模型中所有任务都共享一个内存空间，共享资源通过异步访问该空间读写。系统会通过一些机制，如锁和信号量，来控制共享内存的访问权限。使用这个编程模型的优点是，程序员不需要清楚任务之间通讯的细节。但以性能的角度来说有一个很大的缺陷，那就是难以在局部上理解和管理数据——使数据只有使用它的处理器局部可见从而节省多处理器使用相同数据时的内存访问，Cache刷新和总线传输。

多线程模型
----------

在这个模型中，单个处理器可以有多个执行流程，例如，创建了一个顺序执行任务之后，会创建一系列可以并行执行的任务。通常情况下，这类模型会应用在共享内存架构中。由于多个线程会对共享内存进行操作，所以进行线程间的同步控制是很重要的，作为程序员必须防止多个线程同时修改相同的内存单元。现在的CPU可以在软件和硬件上实现多线程。POSIX 线程就是典型的在软件层面上实现多线程的例子。Intel 的超线程 (Hyper-threading) 技术则在硬件层面上实现多线程，超线程技术主要是当一个线程在停止或等待I/O状态时切换另外一个线程实现的。使用这个模型即使是非线性的数据对齐也能实现并行性。

消息传递模型
------------

消息传递模型通常在分布式内存系统中应用。任务可以由一台或多台物理机器处理。程序员需要确定并行类型和通过消息产生的数据交换。实现这个数据模型需要在代码中调用特定的库。现在有大量消息传递模型的实现，最早的实现可以追溯到20世纪80年代，但直到90年代中期才有事实上的标准化实现——MPI (the message passing interface)。MPI 模型是专门为分布式内存设计的，但作为一个并行编程模型，也可以在共享内存机器上跨平台使用。

.. image:: ../images/Page-15-Image-1.png

数据并行模型
------------

在这个模型中，有多个任务需要操作同一个数据结构，但每一个任务操作的是数据的不同部分。在共享内存架构中，所有任务都通过共享内存来访问数据；在分布式内存架构中则会将数据分割并且保存到每个任务的局部内存中。为了实现着个模型，程序员必须指定数据的分配方式和对齐方式。现在的CPU在数据已对齐的情况下能够自始至终高效运行。

.. image:: ../images/Page-16-Image-1.png